{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle titanic competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my attempt at cracking the titanic challenge posted by Kaggle. I primarily code in Python so it's my obvious language choice.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, they ask us to complete the analysis of what sorts of people were likely to survive.\n",
    "\n",
    "Stick around, it should be fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we first import pandas library and read it in the training data.\n",
    "\n",
    "Download the titanic dataset here: <https://www.kaggle.com/c/titanic>\n",
    "\n",
    "Pandas has a nice built in function to read csv files : **read_csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanic = pd.read_csv('/home/vagrant/titanic/dataset/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**titanic** variable in our case is known as a data frame(df). Representing the object as a data frame will make manipulating the data so much easier, you'll find out later!\n",
    "\n",
    "Print all the columns in the data frame, for reference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'PassengerId', u'Survived', u'Pclass', u'Name', u'Sex', u'Age',\n",
      "       u'SibSp', u'Parch', u'Ticket', u'Fare', u'Cabin', u'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **describe** to get basic statistics of all the columns like count, mean, max, min etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "print titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** As you can see, the count for the `Age` column is less than all other columns, so we need to make a decision here! Either discard the rows which are empty or fill it with some value.\n",
    "\n",
    "We have missing data, in other words!\n",
    "\n",
    "Here, we'll choose the later, we'll fill the empty values with the median `Age` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-numeric Data\n",
    "\n",
    "Several of our columns are non-numeric, which is a problem when it comes time to make predictions -- we can't feed non-numeric columns into a machine learning algorithm and expect it to make sense of them.\n",
    "\n",
    "We have to either exclude our non-numeric columns when we train our algorithm (Name, Sex, Cabin, Embarked, and Ticket), or find a way to convert them to numeric columns.\n",
    "\n",
    "We'll ignore the Ticket, Cabin, and Name columns. There isn't much information we can extract from there. Most of the values in the cabin column are missing (only 204 values out of 891 rows), and it likely isn't a particularly informative column in the first place. The Ticket and Name columns are unlikely to tell us much without some domain knowledge about what the ticket numbers mean, and about which names correlate with characteristics like large or rich families."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the Sex column\n",
    "\n",
    "\n",
    "The Sex column is non-numeric, but we want to keep it around -- it could be very informative. We can convert it to a numeric column by replacing each gender with a numeric code.\n",
    "\n",
    "In our case, we'll replace `female` values with 1 and `male` values with a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "# Find all the unique genders -- the column appears to contain only male and female.\n",
    "print(titanic[\"Sex\"].unique())\n",
    "\n",
    "# Replace all the occurences of male with the number 0.\n",
    "# Replace all the occurences of female with the number 1.\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Converting the Embarked column\n",
    "\n",
    "\n",
    "We now can convert the Embarked column to codes the same way we converted the Sex column. The unique values in Embarked are S, C, Q, and missing (nan). Each letter is an abbreviation of an embarkation port name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "print(titanic[\"Embarked\"].unique())\n",
    "\n",
    "# Replace all the occurences of S,C and Q with the number 0, 1 and 2.\n",
    "# Replace missing values with S (assuming S was the common embarkation port)\n",
    "\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('S')\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Machine Learning section\n",
    "\n",
    "We can now use linear regression to make predictions on our training set.\n",
    "\n",
    "We can use the excellent `scikit-learn` library to make predictions. We'll use a helper from sklearn to split the data up into cross validation folds, and then train an algorithm for each fold, and make predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "#The columns we'll use to predict the target\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "#Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "\n",
    "#Generate cross validation folds for the titanic dataset. It returns the row\n",
    "#indices corresponding to train and test.\n",
    "\n",
    "#We set random state to ensure we get the same splits every time we run this.\n",
    "\n",
    "kf = KFold(titanic.shape[0], n_folds=3,random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_pred = (titanic[predictors].iloc[train,:])\n",
    "    # The target we're using to train.\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    \n",
    "    # Train the algorithm\n",
    "    alg.fit(train_pred, train_target)\n",
    "    \n",
    "    #Test the model\n",
    "    test_pred = alg.predict(titanic[predictors].iloc[test,:])\n",
    "    \n",
    "    predictions.append(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Evaluating Error\n",
    "\n",
    "Now we've done predicting, we need to evaluate our error\n",
    "\n",
    "We'll first define our error metric. \n",
    "\n",
    "The metric will basically involve finding the number of values in `predictions` that are exactly the same as their counterparts in `titanic[\"Survived\"]`, then dividing by the total number of people.\n",
    "\n",
    "Before we do this, we need to combine the 3 sets of predictions into one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three seperate numpy arrays. Concatenate them into one\n",
    "\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes.\n",
    "\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <= .5] = 0\n",
    "\n",
    "lengthOfPredictionsList = len(predictions)\n",
    "sum = 0\n",
    "\n",
    "for i in range(0,lengthOfPredictionsList):\n",
    "    if predictions[i] == titanic[\"Survived\"].iloc[i]:\n",
    "        sum += 1\n",
    "\n",
    "#calculate accuracy\n",
    "\n",
    "accuracy = sum/lengthOfPredictionsList\n",
    "\n",
    "print accuracy # 78.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We have our first predictions! They aren't very good, though, with only 78.3% accuracy.\n",
    "\n",
    "We need to make linear regression values between 0 and 1. This is a technique called logistic regression.\n",
    "\n",
    "Sklearn has a class for logistic regression that we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787878787879\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialization our algorithm\n",
    "\n",
    "alg = LogisticRegression(random_state=1)\n",
    "\n",
    "# Compute the accuracy for all the cross validation folds.\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "\n",
    "# Take the mean of the scores (becuase we have one for each fold)\n",
    "\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process our test test\n",
    "\n",
    "To make a submission, we need to do the exact same steps on the test data that we took on the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test = pd.read_csv(\"/home/vagrant/titanic/dataset/test.csv\")\n",
    "\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna('S')\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a submission file\n",
    "\n",
    "Now that we have everything, it's time to train an algorithm on the training data and unleash it on the test data. Then we can make predictions on the test daata.\n",
    "\n",
    "Finally, we'll generate a csv file with the predictions and passengers ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the algorithm class\n",
    "alg = LogisticRegression(random_state=1)\n",
    "\n",
    "# Train the algorithm using all the training data\n",
    "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Make predictions using the test set.\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "    \n",
    "submission.to_csv(\"/vagrant/kaggle.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
